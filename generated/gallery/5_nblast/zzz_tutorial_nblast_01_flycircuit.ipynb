{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nNBLAST against FlyCircuit\n=========================\n\nThis example demonstrates how to run an NBLAST against the entire FlyCircuit dataset.\n\n!!! important \"This example is not executed\"\n    In contrast to almost all other tutorials, this one is not executed when the documentation is built.\n    Consequently, it also does not show any code output or figures. That's because this example requires\n    downloading a large dataset (~850Mb) and running an NBLAST against it, it is simply not feasible to\n    run this as part of the documentation build process.\n\nIf you work with _Drosophila_, chances are you have heard of [FlyCircuit](http://www.flycircuit.tw). It's a collection of ~16k\nsingle neuron clones published by [Chiang et al. (2010)](https://www.cell.com/current-biology/fulltext/S0960-9822(10)01522-8).\n\nFor R, there is a package containing dotprops and meta data for these neurons: [`nat.flycircuit`](https://github.com/natverse/flycircuit).\nThis does not yet exist for Python. However, it's still pretty straight forward to run an NBLAST against the entire flycircuit dataset in Python!\n\nFirst you need to download flycircuit dotprops from [Zenodo](https://zenodo.org/record/5205616) (~850Mb). Next, unzip the archive containing the\ndotprops as CSV files. Now we we need to load them into {{ navis }} (adjust filepaths as required):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import navis\nimport pandas as pd\n\nfrom pathlib import Path\nfrom tqdm import tqdm\n\ndef load_dotprops_csv(fp):\n    \"\"\"Load dotprops from CSV files in filepath `fp`.\"\"\"\n    # Turn into a path object\n    fp = Path(fp).expanduser()\n\n    # Go over each CSV file\n    files = list(fp.glob('*.csv'))\n    dotprops = []\n    for f in tqdm(files, desc='Loading dotprops', leave=False):\n        # Read file\n        csv = pd.read_csv(f)\n\n        # Each row is a point with associated vector\n        pts = csv[['pt_x', 'pt_y', 'pt_z']].values\n        vect = csv[['vec_x', 'vec_y', 'vec_z']].values\n\n        # Turn into a Dotprops\n        dp = navis.Dotprops(points=pts, k=20, vect=vect, units='1 micron')\n\n        # Use filename as ID/name\n        dp.name = dp.id = f.name[:-4]\n\n        # Add this dotprop to the list before moving on to the next\n        dotprops.append(dp)\n\n    return navis.NeuronList(dotprops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load dotprops from the filepath\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fc_dps = load_dotprops_csv('flycircuit_dotprops')\nfc_dps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n    To avoid having to re-generate these dotprops, you could consider pickling them:\n    ```python\n    import pickle\n    with open('flycircuit_dps.pkl', 'wb') as f:\n        pickle.dump(fc_dps, f)\n    ```\n\n    In the future you can then reload the dotprops like so (much faster than loading from CSV):\n    ```python\n    with open('flycircuit_dps.pkl', 'rb') as f:\n        fc_dps = pickle.load(f)\n    ```\n\nNote: The names/ids correspond to the flycircuit gene + clone names:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fc_dps[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In case your query neurons are in a different brain space, you can use [flybrains](https://github.com/navis-org/navis-flybrains) to\nconvert them to flycircuit's `FCWB` space.\n\nFor demonstration purposes we will use the example neurons - olfactory DA1 projection neurons from the hemibrain connectome - that ship\nwith {{ navis }} and try to find their closest match in the FlyCircuit dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load some of the example neurons\nn = navis.example_neurons(3)\n\n# Convert from hemibrain (JRCFIB2018Fraw) to FCWB space\nimport flybrains\n\nn_fcwb = navis.xform_brain(n, source='JRCFIB2018Fraw', target='FCWB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A sanity check to make sure the transform worked\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = navis.plot2d([n_fcwb, flybrains.FCWB])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FlyCircuit neurons are all on the left side of the brain. We need\nmirror our neurons from the right to the left to match that.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_fcwb_mirr = navis.mirror_brain(n_fcwb, template='FCWB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert our neurons to dotprops\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_dps = navis.make_dotprops(n_fcwb_mirr, resample=1, k=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a \"smart\" NBLAST to get the top hits\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = navis.nblast_smart(query=n_dps, target=fc_dps, scores='mean', progress=False)\nscores.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n    If you get a warning about data not being in microns: that's a rounding error from the transform and can be safely ignored.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Find the top hits for each of our query neurons\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfor dp in n_dps:\n    hit = scores.columns[np.argmax(scores.loc[dp.id].values)]\n    sc = scores.loc[dp.id].values.max()\n    print(f'Top hit for {dp.id}: {hit} ({sc:.3f})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All of our query neurons should have the same top match (they are all from the same cell type after all): `FruMARCM-F001496_seg001`\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's co-visualize:\nQueries in red, hit in black\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = navis.plot2d([n_fcwb_mirr, fc_dps.idx['FruMARCM-F001496_seg001']],\n                       color=['r'] * len(n_fcwb_mirr) + ['k'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking good!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nNBLAST\n======\n\nThis tutorial will introduce you to NBLAST (Costa et al., 2016), a method to compare neurons based on their morphology.\n\n## What is NBLAST?\n\nA brief introduction (modified from Jefferis lab's [website](http://flybrain.mrc-lmb.cam.ac.uk/si/nblast/www/)):\n\nNBLAST works by decomposing neurons into point and tangent vector representations - so called \"dotprops\". Similarity between a\ngiven query and a given target neuron is determined by:\n\n1. Nearest-neighbor search:\n\n    For each point + tangent vector $u_{i}$ of the query neuron, find the closest point + tangent vector $v_{i}$ on the target neuron\n    (this is a simple nearest-neighbor search using Euclidean distance).\n\n    ![NBLAST_neuron_comparison](../../../_static/NBLAST_neuron_comparison.png)\n\n2. Calculate a raw score:\n\n    The raw score is a `weighted` product from the distance $d_{i}$ between the points in each pair and the absolute dot\n    product of the two tangent vectors $| \\vec{u_i} \\cdot \\vec{v_i} |$.\n\n    The absolute dot product is used because the orientation of the tangent vectors typically has no meaning in our data representation.\n\n    A suitable scoring function $f$ was determined empirically (see the [NBLAST paper](http://flybrain.mrc-lmb.cam.ac.uk/si/nblast/www/paper/))\n    and is shipped with {{ navis }} as scoring matrices:\n\n    ![NBLAST_score_mat](../../../_static/NBLAST_score_mat_inv.png)\n\n    Importantly, these matrices were created using _Drosophila_ neurons from the [FlyCircuit](http://flycircuit.tw/) light-level dataset which\n    are in microns. Consequently, you should make sure your neurons are also in micrometer units for NBLAST! If you are working on non-insect\n    neurons you might have to play around with the scaling to improve results. Alternatively, you can also produce your own scoring function\n    (see [this tutorial](../tutorial_nblast_03_smat)).\n\n3. Produce a per-pair score:\n\n    This is done by simply summing up the raw scores over all point + tangent vector pairs for a given query-target neuron pair.\n\n4. Normalize raw score\n\n    This step is optional but highly recommended: normalizing the raw score by dividing by the raw score of a self-self comparison of the query neuron.\n\n\nPutting it all together, the formula for the raw score $S$ is:\n\n$$\nS(query,target)=\\sum_{i=1}^{n}f(d_{i}, |\\vec{u_i} \\cdot \\vec{v_i}|)\n$$\n\n!!! important \"The direction of the comparison matters!\"\n    Consider two very different neurons - one large, one small - that overlap in space. If the small neuron is the query, you will always find\n    a close-by nearest-neighbour among the many points of the large target neuron.\n    Consequently, this small :octicons-arrow-right-24: large comparison will produce a decent NBLAST score. By contrast, the other way around\n    (large :octicons-arrow-right-24: small) will likely produce a bad NBLAST score because many points in the large neuron are far away from the\n    closest point in the small neuron. In practice, we typically use the mean between those forward and the reverse scores. This is done either\n    by running two NBLASTs (query :octicons-arrow-right-24: target and target :octicons-arrow-right-24: query), or by passing e.g. `scores=\"mean\"`\n    to the respective NBLAST function.\n\n## Running NBLAST\n\nBroadly speaking, there are two applications for NBLAST:\n\n1. Matching neurons neurons between two datasets\n2. Clustering neurons into morphologically similar groups\n\nBefore we get our feet wet, two things to keep in mind:\n\n- neurons should be in microns as this is what NBLAST's scoring matrices have been optimized for (see above)\n- neurons should have similar sampling resolution (i.e. points per unit of cable)\n\n??? example \"Speeding up NBLAST\"\n    For a ~2x speed boost, install the [pykdtree](https://github.com/storpipfugl/pykdtree) library: `pip3 install pykdtree`.\n\n    If you installed {{ navis }} with the `pip install navis[all]` option you should already have it.\n\nOK, let's get started!\n\nWe will use the example neurons that come with {{ navis }}. These are all of the same type, so we don't expect to find very useful clusters - good enough to demo though!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load example neurons\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import navis\n\nnl = navis.example_neurons()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NBLAST works on dotprops - these consist of points and tangent vectors decribing the shape of a neuron and are represented by the [`navis.Dotprops`][] class\nin {{ navis }}. You can generate those dotprops from skeletons (i.e. [`TreeNeurons`][navis.TreeNeuron]), meshes (i.e. [`MeshNeurons`][navis.MeshNeuron])\n(see [`navis.make_dotprops`][] for details) or straight from image data (see [`navis.read_nrrd`][] and [`navis.read_tiff`][]) - e.g. confocal stacks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Convert neurons into microns (they are 8nm)\nnl_um = nl / (1000 / 8)\n\n# Generate dotprops\ndps = navis.make_dotprops(nl_um, k=4, resample=False)\n\n# Run the actual NBLAST: the first two vs the last two neurons\nnbl = navis.nblast(dps[:2], dps[2:], progress=False)\nnbl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Painless, wasn't it? The `nbl` scores dataframe has the query neurons as rows and the target neurons as columns.\n\nLet's run an all-by-all NBLAST next:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aba = navis.nblast_allbyall(dps, progress=False)\naba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This demonstrates two things:\n\n1. The forward and reverse scores are never exactly the same (as noted above).\n2. The diagonal is always 1 because it is a self-self comparison (i.e. a perfect match) and we normalize against that.\n\nLet's run some quick & dirty analysis just to illustrate things.\n\nFor hierarchical clustering we need the matrix to be symmetrical - which our all-by-all matrix is not.\nWe will therefore use the mean of forward and reverse scores (you could also use e.g. the minimum or the maximum):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aba_mean = (aba + aba.T) / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also need distances instead of similarities!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Invert to get distances\nBecause our scores are normalized, we know the max similarity is 1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aba_dist = 1 - aba_mean\naba_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can use scipy's hierarchical clustering to generate a dendrogram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import squareform\nfrom scipy.cluster.hierarchy import linkage, dendrogram, set_link_color_palette\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcl\nimport seaborn as sns\n\nset_link_color_palette([mcl.to_hex(c) for c in sns.color_palette(\"muted\", 10)])\n\n# To generate a linkage, we have to bring the matrix from square-form to vector-form\naba_vec = squareform(aba_dist, checks=False)\n\n# Generate linkage\nZ = linkage(aba_vec, method=\"ward\")\n\n# Plot a dendrogram\ndn = dendrogram(Z, labels=aba_mean.columns)\n\nax = plt.gca()\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha=\"right\")\n\nsns.despine(trim=True, bottom=True)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll leave it at that for now but just to have it mentioned: there is also a [`navis.nblast_smart`][] function which tries to cut some corners and may\nbe useful if you want to run very large NBLASTs.\n\nThese are the functions we seen so far:\n\n- [`navis.nblast`][]: classic query :octicons-arrow-right-24: target NBLAST\n- [`navis.nblast_allbyall`][]: pairwise, all-by-all NBLAST\n- [`navis.nblast_smart`][]: a \"smart\" version of NBLAST\n\n## Another flavour: syNBLAST\n\nSyNBLAST is synapse-based NBLAST: instead of turning neurons into dotprops, we use their synapses to perform NBLAST (minus the vector component).\nThis is generally faster because we can skip generating dotprops and calculating vector dotproducts. It also focusses the attention on the synapse-bearing\naxons and dendrites, effectively ignoring the backbone.\nThis changes the question from \"_Do neurons look the same?_\" to \"_Do neurons have in- and output in the same area?_\". See [`navis.synblast`][] for details.\n\nLet's try the above but with syNBLAST:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Importantly, we still want to use data in microns!\nsynbl = navis.synblast(nl_um, nl_um, by_type=True, progress=False)\nsynbl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same as above, we can run an all-by-all synNBLAST and generate a dendrogram:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "aba_vec = squareform(((synbl + synbl.T) / 2 - 1) * -1, checks=False)\n\nZ = linkage(aba_vec, method=\"ward\")\n\ndn = dendrogram(Z, labels=synbl.columns)\n\nax = plt.gca()\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha=\"right\")\n\nsns.despine(trim=True, bottom=True)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A real-world example\n\nThe toy data above is not really suited to demonstrate NBLAST because these neurons are of the same type (i.e. we do not expect to see differences).\n\nLet's try something more elaborate and pull some hemibrain neurons from [neuPrint](https://neuprint.janelia.org/). For this you need to install the\n`neuprint-python` package (`pip3 install neuprint-python`), make a neuPrint account and generate/set an authentication token. Sounds complicated\nbut is all pretty painless - see the [neuPrint documentation](https://connectome-neuprint.github.io/neuprint-python/docs/quickstart.html) for details.\nThere is also a separate {{ navis }} tutorial on neuprint [here](../4_remote/tutorial_remote_00_neuprint).\n\nOnce that's done we can get started by importing the neuPrint interface from {{ navis }}:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import navis.interfaces.neuprint as neu\n\n# Set a client\nclient = neu.Client(\"https://neuprint.janelia.org\", dataset=\"hemibrain:v1.2.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we will fetch all olfactory projection neurons of the lateral lineage using a regex pattern.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pns = neu.fetch_skeletons(\n    neu.NeuronCriteria(type=\".*lPN.*\", regex=True), with_synapses=True, client=client\n)\n\n# Drop neurons on the left hand side\npns = pns[[not n.name.endswith(\"_L\") for n in pns]]\n\npns.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate dotprops\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# These neurons are in 8x8x8nm (voxel) resolution\npns_um = pns / (1000 / 8)  # convert to microns\npns_dps = navis.make_dotprops(pns_um, k=5)\npns_dps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run an all-by-all NBLAST and synNBLAST\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pns_nbl = navis.nblast_allbyall(pns_dps, progress=False)\npns_synbl = navis.synblast(pns_um, pns_um, by_type=True, progress=False)\n\n# Generate the linear vectors\nnbl_vec = squareform(((pns_nbl + pns_nbl.T) / 2 - 1) * -1, checks=False)\nsynbl_vec = squareform(((pns_synbl + pns_synbl.T) / 2 - 1) * -1, checks=False)\n\n# Generate linkages\nZ_nbl = linkage(nbl_vec, method=\"ward\", optimal_ordering=True)\nZ_synbl = linkage(synbl_vec, method=\"ward\", optimal_ordering=True)\n\n# Plot dendrograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\ndn1 = dendrogram(Z_nbl, no_labels=True, color_threshold=1, ax=axes[0])\ndn2 = dendrogram(Z_synbl, no_labels=True, color_threshold=1, ax=axes[1])\n\naxes[0].set_title(\"NBLAST\")\naxes[1].set_title(\"synNBLAST\")\n\nsns.despine(trim=True, bottom=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While we don't know which leaf is which, the structure in both dendrograms looks similar. If we wanted to take it further than that, we could use\n[tanglegram](https://github.com/schlegelp/tanglegram) to line up the two clusterings and compare them.\n\nBut let's save that for another day and instead do some plotting:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate clusters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import fcluster\n\ncl = fcluster(Z_synbl, t=1, criterion=\"distance\")\ncl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now plot each cluster. For simplicity we are plotting in 2D here:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\n\nn_clusters = max(cl)\nrows = 4\ncols = math.ceil(n_clusters / 4)\nfig, axes = plt.subplots(rows, cols, figsize=(20, 5 * cols))\n# Flatten axes\naxes = [ax for l in axes for ax in l]\n\n# Generate colors\npal = sns.color_palette(\"muted\", n_clusters)\n\nfor i in range(n_clusters):\n    ax = axes[i]\n    ax.set_title(f\"cluster {i + 1}\")\n    # Get the neurons in this cluster\n    this = pns[cl == (i + 1)]\n\n    navis.plot2d(\n        this, method=\"2d\", ax=ax, color=pal[i], lw=1.5, view=(\"x\", \"-z\"), alpha=0.5\n    )\n\nfor ax in axes:\n    ax.set_aspect(\"equal\")\n    ax.set_axis_off()\n\n    # Set all axes to the same limits\n    bbox = pns.bbox\n    ax.set_xlim(bbox[0][0], bbox[0][1])\n    ax.set_ylim(bbox[2][1], bbox[2][0])\n\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note how clusters 3 and 8 look a bit odd? That's because these likely still contain more than one type of neuron. We should probably\nhave gone with a slightly finer clustering. But this little demo should be enough to get you started!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
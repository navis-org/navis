{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nNeuroglancer & CloudVolume\n==========================\n\nThis tutorial will show you how to pull data from `Neuroglancer` using [`CloudVolume`](https://github.com/seung-lab/cloud-volume).\n\n[Neuroglancer](https://github.com/google/neuroglancer) is a WebGL-based viewer for volumetric data. You may have used it to browse\nsome of the recent large EM datasets. If you want to programmatically access/download these data, you need\n[CloudVolume](https://github.com/seung-lab/cloud-volume). `CloudVolume` is an excellent Python library developed by\nWilliam Silversmith (Seung lab, Princeton) and others. While `CloudVolume` is not directly related to `Neuroglancer`,\nit shares much of its functionality. As a rule of thumb: if you can view a dataset in `Neuroglancer`, you can download\nthat data using `CloudVolume`. For example:\n\n1. [FlyWire](https://flywire.ai/) is a segmentation of an entire *Drosophila* brain. This dataset is very much work in progress and you\n   will to register and apply for access. Check out [FAFBseg](https://fafbseg-py.readthedocs.io) for a fairly mature interface built on\n   top of {{ navis }}.\n2. [Google's flood-filling segmentation](http://fafb-ffn1.storage.googleapis.com/landing.html) of an entire *Drosophila* brain.\n3. The Allen Institute's [MICrONs datasets](https://www.microns-explorer.org/). We have a separate [tutorial](../tutorial_remote_02_microns) on this!\n4. The Janelia [hemibrain connectome](https://neuprint.janelia.org).\n\nYou can find the find the source for the data you want to access by right-clicking on the layer in question and selecting the \"Source\" tab on the right:\n\n![Neuroglancer source](../../../_static/neuroglancer_source.png)\n\n`CloudVolume` supports pretty much all the backends/data formats that neuroglancer does. You can use it to programmatically query the segmentation itself,\nand to fetch meshes and skeletons (if available). {{ navis }} & friends provide simple interfaces for some of the datasets (see e.g. the\nneuPrint and the MICrONs tutorials) but there is also some lower-level option to pull neurons into {{ navis }} via `CloudVolume`.\n\nFirst of all, you will want to make sure to `cloud-volume` is installed and up-to-date:\n\n```shell\npip install cloud-volume -U\n```\n\nOnce that's done we can start pulling data using `cloud-volume`. In this example here, we will use the Google segmentation of the FAFB dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import navis\nimport cloudvolume as cv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Before* we connect to the datasource we have to \"monkey patch\" `cloudvolume` using [`navis.patch_cloudvolume`][]. That will\nteach `cloudvolume` to return {{ navis }} neurons:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This needs to be run only once at the beginning of each session\nnavis.patch_cloudvolume()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can connect to our data source. Here we connect to the Google segmentation of the FAFB dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Don't forget to set `use_https=True` to avoid having to setup Google credentials!\nvol = cv.CloudVolume(\n    \"precomputed://gs://fafb-ffn1-20200412/segmentation\", use_https=True, progress=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fetch neuron meshes:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Setting `as_navis=True` we will get us MeshNeurons\nm = vol.mesh.get([4335355146, 2913913713, 2137190164, 2268989790], as_navis=True, lod=3)\nm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note \"Shortcut\"\n    Instead of `vol.mesh.get(..., as_navis=True)` you can also use the shortcut\n    `vol.mesh.get_navis(...)` which is equivalent.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "navis.plot3d(\n    m,\n    legend_orientation=\"h\",  # few neurons, so we can afford a horizontal legend\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# And one 2D plot (for the tutorial thumbnail)\nimport matplotlib.pyplot as plt\n\nfig, ax = navis.plot2d(m[1], method=\"2d\", view=(\"x\", \"-y\"))\nax.set_axis_off()\nax.grid(False)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This also works for skeletons:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sk = vol.skeleton.get([4335355146, 2913913713, 2137190164, 2268989790], as_navis=True)\nsk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that not all datasets contain precomputed skeletons! In that case you\ncould download the meshes and use [`navis.skeletonize`][] to skeletonize them.\n\n!!! experiment \"Try it out!\"\n    If you are working a lot with NeuroGlancer and need to e.g. generated or parse URLs, you might want to check out the\n    [`nglscenes`](https://github.com/schlegelp/nglscenes) package.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
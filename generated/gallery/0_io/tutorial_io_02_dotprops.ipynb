{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDotprops\n========\n\nThis tutorial will show you how to load/create Dotprops.\n\n[`navis.Dotprops`][] are point clouds with associated principal vectors which are mostly used for\nNBLASTing. They are typically derivatives of skeletons or meshes but you can load them straight from\ne.g. confocal image stacks using [`navis.read_nrrd`][] or [`navis.read_tiff`][].\n\n![dotprops](../../../../_static/dotprops.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import navis\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## From image data\n\nFor this example we will use a stack from [Janelia's split Gal4 collection](https://splitgal4.janelia.org/).\nThis `LH2094` line is also available from [Virtual Fly Brain](https://v2.virtualflybrain.org/org.geppetto.frontend/geppetto?id=VFB_00102926&i=VFB_00101567,VFB_00102926)\nwhere, conveniently, they can be downloaded in NRRD format which we can directly read into {{ navis }}.\n\nLet's do this step-by-step first:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Load raw NRRD image\nim, header = navis.read_nrrd(\n    \"https://v2.virtualflybrain.org/data/VFB/i/0010/2926/VFB_00101567/volume.nrrd\",\n    output=\"raw\"\n)\n\n# Plot a maximum projection\nmax_proj = im.max(axis=2)\nplt.imshow(\n    max_proj.T,\n    extent=(0, int(0.5189 * 1210), (0.5189 * 566), 0),  # extent is calculated from the spacing (see `header`) times the no of x/y pixels\n    cmap='Greys_r',\n    vmax=10  # make it really bright so we can see neurons + outline of the brain\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At this point we could threshold the image, extract above-threshold voxels and convert them to a Dotprops object.\nHowever, the easier option is to use [`navis.read_nrrd`][] with the `output=\"dotprops\"` parameter:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dp = navis.read_nrrd(\n    \"https://v2.virtualflybrain.org/data/VFB/i/0010/2926/VFB_00101567/volume.nrrd\",\n    output=\"dotprops\",\n    threshold=5,  # threshold to determine which voxels are used for the dotprops\n    thin=True,   # see note below on this parameter!\n    k=10  # number of neighbours to consider when calculating the tangent vector\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note \"Thinning\"\n    In the above [`read_nrrd`][navis.read_nrrd] call we used `thin=True`. This is a post-processing step that\n    thins the image to a single pixel width. This will produce \"cleaner\" dotprops but can also remove denser\n    neurites thus emphasizing the backbone of the neuron. This option requires the `scikit-image` package:\n\n    ```bash\n    pip install scikit-image\n    ```\n\n Let's overlay the dotprops on the maximum projection:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.imshow(\n    max_proj.T,\n    extent=(0, int(0.5189 * 1210), (0.5189 * 566), 0),\n    cmap='Greys_r',\n    vmax=10\n    )\nnavis.plot2d(dp, ax=ax, view=(\"x\", \"-y\"), method=\"2d\", color=\"r\", linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This looks pretty good but we have a bit of little fluff around the brain which we may want to get rid off:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Drop everything but the two largest connected components\ndp = navis.drop_fluff(dp, n_largest=2)\n\n# Plot again\nfig, ax = plt.subplots()\nax.imshow(\n    max_proj.T,\n    extent=(0, int(0.5189 * 1210), (0.5189 * 566), 0),\n    cmap='Greys_r',\n    vmax=10\n    )\nnavis.plot2d(dp, ax=ax, view=(\"x\", \"-y\"), method=\"2d\", color=\"r\", linewidth=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n    To extract the connected components, [`navis.drop_fluff`][] treats all pairs of points within a certain distance\n    as connected. The distance is determined by the `dp_dist` parameter which defaults to 5 x the average distance\n    between points. That is a good value for this example but you may need adjust it for your data.\n\n\n## From other neurons\n\nLet's say you have a bunch of skeletons and you need to convert them to dotprops for NBLAST. For that you\n[`navis.make_dotprops`][]:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sk = navis.example_neurons(3, kind=\"skeleton\")\ndp = navis.make_dotprops(sk, k=5)\n\n# Plot one of the dotprops\nfig, ax = navis.plot2d(dp[0], view=(\"x\", \"-z\"), method=\"2d\", color=\"red\")\n\n# Add a zoom-in\naxins = ax.inset_axes([0.03, 0.03, 0.47, 0.47], xticklabels=[], yticklabels=[])\n_ = navis.plot2d(dp[0], view=(\"x\", \"-z\"), method=\"2d\", color=\"red\", ax=axins)\naxins.set_xlim(17e3, 19e3)\naxins.set_ylim(15e3, 13e3)\nax.indicate_inset_zoom(axins, edgecolor=\"black\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n    The `k` parameter in [`make_dotprops`][navis.make_dotprops] determines how many neighbours are considered to\n    generated the tangent vector for a given point.\n    Higher `k` = smoother. Lower `k` = more detailed but also more noisy. If you have clean data such as these\n    connectome-derived skeletons, you can go with a low `k`. For confocal data, you might want to go with a higher `k`\n    (e.g. 20) to smooth out the noise. You can pass `k` to [`navis.read_nrrd`][] as well.\n\n## Manual construction\n\nIf not loaded from file, you would typically create [`Dotprops`][navis.Dotprops] via [`navis.make_dotprops`][] but just\nlike all other neuron types, [`Dotprops`][navis.Dotprops] can be constructed manually:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n# Create some x/y/z coordinates\npoints = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2]])\n\n# Create vectors for each point\n# You can skip this point and just provide the `k` parameter\nvect = np.array([[1, 0, 0], [0, 1, 0], [0, 1, 0]])\n\ndp = navis.Dotprops(points, k=None, vect=vect)\ndp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is no established format to store dotprops. But like all other neuron types in navis, you can pickle data for later (re)use\n- see the [pickling tutorial](../tutorial_io_04_pickle). See also the [I/O API reference](../../../api.md#importexport).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}